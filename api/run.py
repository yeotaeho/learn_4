"""ë¡œì»¬ì—ì„œ FastAPI ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸."""

import os
import sys
from pathlib import Path

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import uvicorn

# Neon PostgreSQL ê¸°ë³¸ URL
NEON_DATABASE_URL = (
    "postgresql://neondb_owner:npg_pzP8wiQDH1sk@"
    "ep-autumn-boat-a1wcjk8g-pooler.ap-southeast-1.aws.neon.tech/"
    "neondb?sslmode=require"
)

if __name__ == "__main__":
    # run.py íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ model_weights ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œ)
    run_file_dir = Path(__file__).parent.absolute()
    model_weights_path = run_file_dir / "model_weights"

    # í™˜ê²½ë³€ìˆ˜ ê¸°ë³¸ê°’ ì„¤ì • (OpenAI ì‚¬ìš©)
    os.environ.setdefault("LLM_PROVIDER", "openai")
    os.environ.setdefault("OPENAI_MODEL", "gpt-4o-mini")
    os.environ.setdefault("OPENAI_TEMPERATURE", "0.7")
    os.environ.setdefault("DATABASE_URL", NEON_DATABASE_URL)

    # ê°œë°œ ëª¨ë“œ ì„¤ì •
    debug = os.getenv("DEBUG", "true").lower() == "true"

    print("ğŸš€ ì„œë²„ ì‹œì‘...")
    print(f"ğŸ“¦ LLM Provider: {os.getenv('LLM_PROVIDER')}")
    if os.getenv("LLM_PROVIDER", "openai") == "openai":
        print(f"ğŸ¤– OpenAI Model: {os.getenv('OPENAI_MODEL', 'gpt-4o-mini')}")
        if not os.getenv("OPENAI_API_KEY"):
            print("âš ï¸  ê²½ê³ : OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        print(f"ğŸ“‚ Model Path: {os.getenv('LOCAL_MODEL_PATH', 'N/A')}")
    print(f"ğŸ—„ï¸  Database: Neon PostgreSQL (ap-southeast-1)")
    print(f"ğŸ”§ Debug Mode: {debug}")
    print()

    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=debug,
        log_level="info",
    )
